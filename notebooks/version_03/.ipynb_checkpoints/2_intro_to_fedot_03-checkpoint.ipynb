{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72539c3b",
   "metadata": {},
   "source": [
    "# FEDOT framework\n",
    "#### FEDOT version = 0.3\n",
    "\n",
    "Below is a description of the FEDOT framework and its main functions, which can be used to solve various ML tasks, namely:\n",
    "\n",
    "* Regression\n",
    "* Classification\n",
    "* Time series forecasting\n",
    "* Clustering\n",
    "\n",
    "FEDOT can construct complex composite models (consisting of multiple machine learning models and preprocessing operations) based on an evolutionary algorithm. Thus, it is possible to create pipelines for solving various tasks.\n",
    "\n",
    "The structure of the FEDOT framework can be seen in the figure below:\n",
    "\n",
    "![fedot_structure.png](../jupyter_media/fedot_structure/fedot_structure_03.png)\n",
    "\n",
    "Figure 1. The structure of the FEDOT framework. The main modules of the library are shown.\n",
    "\n",
    "As you can see from the picture there are two ways to start FEDOT:\n",
    "1) API - allows you to run framework models in a few lines of code;\n",
    "2) Low-level methods from the core - you can call methods by accessing the core directly. In this case, you will have to write more code, but more functionality opens up.\n",
    "\n",
    "## Composite models\n",
    "\n",
    "FEDOT has following abstractions:\n",
    "* Operation - is a machine learning model or preprocessing operation or statistical models;\n",
    "* Node - is a container in which the operation is placed. A single node can contain only one operation;\n",
    "* Chain - is a container that hosts nodes. Chains are complex composite models. A single chain can consist of multiple nodes, or a single node.\n",
    "\n",
    "![operation_node_chain.png](../jupyter_media/fedot_structure/operation_node_chain.png)\n",
    "\n",
    "## Generate synthetic dataset for classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d244bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features table shape: (250, 3), type: <class 'numpy.ndarray'>\n",
      "Target vector: (250,), type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from fedot.utilities.synth_dataset_generator import classification_dataset\n",
    "from sklearn.metrics import roc_auc_score as roc_auc\n",
    "\n",
    "# Generate numpy arrays with features and target\n",
    "features_options = {'informative': 1, 'redundant': 0,\n",
    "                    'repeated': 0, 'clusters_per_class': 1}\n",
    "x_data, y_data = classification_dataset(samples_amount=250,\n",
    "                                        features_amount=3,\n",
    "                                        classes_amount=2,\n",
    "                                        features_options=features_options)\n",
    "\n",
    "print(f'Features table shape: {x_data.shape}, type: {type(x_data)}')\n",
    "print(f'Target vector: {y_data.shape}, type: {type(y_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65908add-2495-4583-b4d0-6b5d932f6292",
   "metadata": {},
   "source": [
    "## Manual chain \n",
    "\n",
    "Below, we will try to set the chain manually, and give a prediction using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c7cef0-c56a-41df-969e-672387eee27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create chain\n",
    "from fedot.core.chains.chain import Chain\n",
    "from fedot.core.chains.node import PrimaryNode, SecondaryNode\n",
    "\n",
    "# Tasks to solve\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum\n",
    "\n",
    "# Dataclass for wrapping arrays into it\n",
    "from fedot.core.data.data import InputData\n",
    "\n",
    "# Type of the input data\n",
    "from fedot.core.repository.dataset_types import DataTypesEnum\n",
    "\n",
    "# Define classification task\n",
    "task = Task(TaskTypesEnum.classification)\n",
    "\n",
    "# Prepare data to train the model\n",
    "input_data = InputData(idx=np.arange(0, len(x_data)), features=x_data,\n",
    "                       target=y_data, task=task,\n",
    "                       data_type=DataTypesEnum.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5b921-7dd2-4977-8a61-c98aa4aca58d",
   "metadata": {},
   "source": [
    "Manually create a chain of the following configuration:\n",
    "\n",
    "![logit_scaling_lda.png](../jupyter_media/fedot_structure/logit_scaling_lda.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "599bd71a-345d-49a1-94ba-1c02b8de8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on training sample: 0.903\n"
     ]
    }
   ],
   "source": [
    "# Define chain \n",
    "node_logit = PrimaryNode('logit')\n",
    "node_scaling = PrimaryNode('scaling')\n",
    "node_logit = SecondaryNode('lda', nodes_from=[node_logit, node_scaling])\n",
    "chain = Chain(node_logit)\n",
    "\n",
    "# Fit it\n",
    "chain.fit(input_data)\n",
    "\n",
    "# Make prediction\n",
    "predicted_output = chain.predict(input_data)\n",
    "probs = np.array(predicted_output.predict)\n",
    "\n",
    "# Check metric value\n",
    "print(f'ROC AUC score on training sample: {roc_auc(y_data, probs):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce625e7d-b784-43f3-8560-c866d5ea4457",
   "metadata": {},
   "source": [
    "This is how you learned the concept of chains in FEDOT.\n",
    "\n",
    "But FEDOT can automatically construct such chains to solve the task.\n",
    "\n",
    "Below are two examples for solving the classification task (with such chains) using API methods and using FEDOT.core function directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efda7d2f",
   "metadata": {},
   "source": [
    "## API example\n",
    "\n",
    "Using the API allows you to find good solutions using a few lines of code, but on the other hand, this approach has less abilities for modification than using core-based methods.\n",
    "\n",
    "*Due to the specifics of the jupiter notebooks format, in order not to overload the page with unnecessary logs, we do not show the cell output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f9549-9b2a-45e0-96e0-a011a4ed94c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fedot.api.main import Fedot\n",
    "\n",
    "# Task selection, initialisation of the framework\n",
    "fedot_model = Fedot(problem='classification', learning_time=1,\n",
    "                    seed=20, verbose_level=4)\n",
    "\n",
    "# During fit, the chain composition algorithm is started\n",
    "pipeline = fedot_model.fit(features=x_data,\n",
    "                           target=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f5b1edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 2, 'length': 2, 'nodes': [xgboost, scaling]}\n",
      "ROC AUC score on training sample: 0.986\n"
     ]
    }
   ],
   "source": [
    "prediction = fedot_model.predict_proba(features=x_data)\n",
    "print(pipeline)\n",
    "print(f'ROC AUC score on training sample: {roc_auc(y_data, prediction):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5cbfc6",
   "metadata": {},
   "source": [
    "## Core-based example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc03e667",
   "metadata": {},
   "source": [
    "We will transform the data into a specific format (InputData) for the algorithm launch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2760a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np \n",
    "\n",
    "# Dataclass for wrapping arrays into it\n",
    "from fedot.core.data.data import InputData\n",
    "\n",
    "# Tasks to solve\n",
    "from fedot.core.repository.tasks import Task, TaskTypesEnum\n",
    "\n",
    "# Type of the input data\n",
    "from fedot.core.repository.dataset_types import DataTypesEnum\n",
    "\n",
    "# Repository with operations in the FEDOT\n",
    "from fedot.core.repository.operation_types_repository import get_operations_for_task\n",
    "\n",
    "# Chain of the FEDOT\n",
    "from fedot.core.chains.chain import Chain\n",
    "\n",
    "# Evolutionary algorithm classes \n",
    "from fedot.core.composer.gp_composer.gp_composer import GPComposerBuilder, GPComposerRequirements\n",
    "from fedot.core.composer.optimisers.gp_comp.gp_optimiser import GPChainOptimiserParameters, GeneticSchemeTypesEnum\n",
    "from fedot.core.repository.quality_metrics_repository import ClassificationMetricsEnum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8317004",
   "metadata": {},
   "source": [
    "Let's define the task that we plan to solve-classification\n",
    "\n",
    "We will also wrap the data in a special structure-Input Data, where we will assign features, specify target, pass the data type (table) and the specified type of the task to be solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0f48cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification task\n",
    "task = Task(TaskTypesEnum.classification)\n",
    "\n",
    "# Prepare data to train the model\n",
    "input_data = InputData(idx=np.arange(0, len(x_data)), features=x_data,\n",
    "                       target=y_data, task=task,\n",
    "                       data_type=DataTypesEnum.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25809823",
   "metadata": {},
   "source": [
    "Now we have identified the data and the task within which we will look for a solution.\n",
    "\n",
    "Next, we want to find a composite model (chain) of such a structure that predicts class labels as accurately as possible. We can determine from which models we can assemble such chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "957d1900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logit', 'lda', 'qda', 'dt', 'rf', 'mlp', 'knn', 'xgboost', 'bernb']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The search of the models provided by the framework that can be used as nodes in a chain for the selected task\n",
    "available_model_types = get_operations_for_task(task=task, mode='models')\n",
    "available_model_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541dd9f5",
   "metadata": {},
   "source": [
    "Let's set the metric that we will use during the evolution process, select \"ROCAUC_penalty\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ec08f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The choice of the metric for the chain quality assessment during composition\n",
    "metric_function = ClassificationMetricsEnum.ROCAUC_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c345f2",
   "metadata": {},
   "source": [
    "#### GPComposer\n",
    "\n",
    "GPComposer is a genetic algorithm that allows you to search for optimal solutions by composing the chains of single machine learning models. \n",
    "\n",
    "Through GPComposerRequirements, we can set some hyperparameters to adjust the behavior of the evolutionary algorithm.\n",
    "\n",
    "With the help of GPComposerRequirements, you can manage:\n",
    "* types of models that can be inserted into primary nodes\n",
    "* types of models that can be inserted into secondary nodes\n",
    "* mutation probability\n",
    "* crossover probability\n",
    "* arity of directed acyclic graph (DAG)\n",
    "* maximum depth of the found chain\n",
    "* time to find a solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e09ae23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The choice and initialisation of the GP search\n",
    "max_lead_time = datetime.timedelta(minutes=5)\n",
    "composer_requirements = GPComposerRequirements(\n",
    "    primary=available_model_types,\n",
    "    secondary=available_model_types, \n",
    "    max_arity=3,\n",
    "    max_depth=3, pop_size=10,\n",
    "    num_of_generations=10,\n",
    "    crossover_prob=0.8, \n",
    "    mutation_prob=0.8, \n",
    "    max_lead_time=max_lead_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6845bbb",
   "metadata": {},
   "source": [
    "Below we will define the genetic scheme of the algorithm. \n",
    "\n",
    "There are several schemes:\n",
    "* steady_state - evolutionary scheme, also known as $(µ+λ)$. New population is generated by using a selection operator which is applied to the union of the offspring and the previous population;\n",
    "* generational - the offspring completely replaces the parent population;\n",
    "* parameter_free - steady-state evolutionary scheme, but $µ$ (population size) changes during evolution like the Fibonacci sequence and $λ$ always equals to the previous item of the sequence with respect to $µ$.\n",
    "\n",
    "For more information you can check [preprint](https://arxiv.org/abs/2103.01301).\n",
    "\n",
    "We will also use the GPComposerBuilder structure, which allows you to set parameters in GPComposer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "30c5a77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop size: 13, num of new inds: 8\n",
      "Best metric is -0.830108\n",
      "Generation num: 0\n",
      "max_depth: 3, no improvements: 0\n",
      "pop size: 21, num of new inds: 13\n",
      "spent time: 0.2 min\n",
      "Best metric is -0.830108\n",
      "Generation num: 1\n",
      "max_depth: 3, no improvements: 1\n",
      "pop size: 34, num of new inds: 21\n",
      "spent time: 0.2 min\n",
      "Best metric is -0.830108\n",
      "Generation num: 2\n",
      "max_depth: 3, no improvements: 2\n",
      "pop size: 34, num of new inds: 21\n",
      "spent time: 0.3 min\n",
      "Best metric is -0.8370753333333333\n",
      "Generation num: 3\n",
      "max_depth: 3, no improvements: 0\n",
      "pop size: 55, num of new inds: 34\n",
      "spent time: 0.3 min\n",
      "Best metric is -0.8370753333333333\n",
      "Generation num: 4\n",
      "max_depth: 3, no improvements: 1\n",
      "pop size: 55, num of new inds: 34\n",
      "spent time: 0.5 min\n",
      "Best metric is -0.8639493333333333\n",
      "Generation num: 5\n",
      "max_depth: 3, no improvements: 0\n",
      "pop size: 55, num of new inds: 34\n",
      "spent time: 0.7 min\n",
      "Best metric is -0.8639493333333333\n",
      "Generation num: 6\n",
      "max_depth: 3, no improvements: 1\n",
      "pop size: 55, num of new inds: 34\n",
      "spent time: 0.8 min\n",
      "Best metric is -0.8649446666666667\n",
      "Generation num: 7\n",
      "max_depth: 3, no improvements: 0\n",
      "pop size: 55, num of new inds: 34\n",
      "spent time: 1.0 min\n",
      "Best metric is -0.8739026666666667\n",
      "Generation num: 8\n",
      "max_depth: 3, no improvements: 0\n",
      "pop size: 55, num of new inds: 34\n",
      "spent time: 1.2 min\n",
      "Best metric is -0.8739026666666667\n",
      "Result:\n",
      "Best metric is -0.8739026666666667\n",
      "Composition time: 1.181 min\n",
      "GP composition finished\n"
     ]
    }
   ],
   "source": [
    "# GP optimiser parameters choice\n",
    "scheme_type = GeneticSchemeTypesEnum.parameter_free\n",
    "optimiser_parameters = GPChainOptimiserParameters(genetic_scheme_type=scheme_type)\n",
    "\n",
    "# Create builder for composer and set composer params\n",
    "builder = GPComposerBuilder(task=task).\\\n",
    "    with_requirements(composer_requirements).\\\n",
    "    with_metrics(metric_function).\\\n",
    "    with_optimiser_parameters(optimiser_parameters)\n",
    "\n",
    "# Create GP-based composer\n",
    "composer = builder.build()\n",
    "\n",
    "# the optimal chain generation by composition - the most time-consuming task\n",
    "chain_evo_composed = composer.compose_chain(data=input_data,\n",
    "                                            is_visualise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacdffc1",
   "metadata": {},
   "source": [
    "We got a chain of several machine learning models. But in the course of evolution, the hyperparameters of these models did not change. Now, within the given topology, we will optimize the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aeeff711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start tuning of primary nodes\n",
      "Hyperparameters optimization start\n",
      "Fit chain from scratch\n",
      "  0%|                                                                           | 0/50 [00:00<?, ?trial/s, best loss=?]Fit chain from scratch\n",
      "  2%|▉                                               | 1/50 [00:00<00:14,  3.39trial/s, best loss: -0.8685897435897436]Fit chain from scratch\n",
      "  4%|█▉                                              | 2/50 [00:00<00:14,  3.38trial/s, best loss: -0.8701923076923077]Fit chain from scratch\n",
      "  6%|██▉                                             | 3/50 [00:00<00:13,  3.39trial/s, best loss: -0.8701923076923077]Fit chain from scratch\n",
      "  8%|████▉                                                        | 4/50 [00:01<00:13,  3.29trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 10%|██████                                                       | 5/50 [00:01<00:13,  3.32trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 12%|███████▎                                                     | 6/50 [00:01<00:13,  3.26trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 14%|████████▌                                                    | 7/50 [00:02<00:13,  3.22trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 16%|█████████▊                                                   | 8/50 [00:02<00:12,  3.26trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 18%|██████████▉                                                  | 9/50 [00:02<00:12,  3.23trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 20%|████████████                                                | 10/50 [00:03<00:12,  3.20trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 22%|█████████████▏                                              | 11/50 [00:03<00:12,  3.20trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 24%|██████████████▍                                             | 12/50 [00:03<00:11,  3.25trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 26%|███████████████▌                                            | 13/50 [00:04<00:11,  3.10trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 28%|████████████████▊                                           | 14/50 [00:04<00:11,  3.18trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 30%|██████████████████                                          | 15/50 [00:04<00:10,  3.22trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 32%|███████████████████▏                                        | 16/50 [00:04<00:10,  3.21trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 34%|████████████████████▍                                       | 17/50 [00:05<00:10,  3.19trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 36%|█████████████████████▌                                      | 18/50 [00:05<00:10,  3.20trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 38%|██████████████████████▊                                     | 19/50 [00:05<00:09,  3.19trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 40%|████████████████████████                                    | 20/50 [00:06<00:09,  3.23trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 42%|█████████████████████████▏                                  | 21/50 [00:06<00:08,  3.23trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 44%|██████████████████████████▍                                 | 22/50 [00:06<00:08,  3.19trial/s, best loss: -0.875]Fit chain from scratch\n",
      " 46%|█████████████████████▌                         | 23/50 [00:07<00:08,  3.19trial/s, best loss: -0.8758012820512822]Fit chain from scratch\n",
      " 48%|██████████████████████▌                        | 24/50 [00:07<00:08,  3.16trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 50%|███████████████████████▌                       | 25/50 [00:07<00:07,  3.13trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 52%|████████████████████████▍                      | 26/50 [00:08<00:07,  3.08trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 54%|█████████████████████████▍                     | 27/50 [00:08<00:07,  3.06trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 56%|██████████████████████████▎                    | 28/50 [00:08<00:07,  3.06trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 58%|███████████████████████████▎                   | 29/50 [00:09<00:06,  3.04trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 60%|████████████████████████████▏                  | 30/50 [00:09<00:06,  3.05trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 62%|█████████████████████████████▏                 | 31/50 [00:09<00:06,  3.03trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 64%|██████████████████████████████                 | 32/50 [00:10<00:05,  3.04trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 66%|███████████████████████████████                | 33/50 [00:10<00:05,  3.03trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 68%|███████████████████████████████▉               | 34/50 [00:10<00:05,  3.02trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 70%|████████████████████████████████▉              | 35/50 [00:11<00:04,  3.02trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 72%|█████████████████████████████████▊             | 36/50 [00:11<00:04,  3.04trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 74%|██████████████████████████████████▊            | 37/50 [00:11<00:04,  3.04trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 76%|███████████████████████████████████▋           | 38/50 [00:12<00:03,  3.04trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 78%|████████████████████████████████████▋          | 39/50 [00:12<00:03,  3.04trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 80%|█████████████████████████████████████▌         | 40/50 [00:12<00:03,  3.02trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 82%|██████████████████████████████████████▌        | 41/50 [00:13<00:02,  3.03trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 84%|███████████████████████████████████████▍       | 42/50 [00:13<00:02,  3.01trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 86%|████████████████████████████████████████▍      | 43/50 [00:13<00:02,  2.92trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 88%|█████████████████████████████████████████▎     | 44/50 [00:14<00:01,  3.03trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 90%|██████████████████████████████████████████▎    | 45/50 [00:14<00:01,  3.05trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 92%|███████████████████████████████████████████▏   | 46/50 [00:14<00:01,  3.09trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 94%|████████████████████████████████████████████▏  | 47/50 [00:15<00:00,  3.06trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 96%|█████████████████████████████████████████████  | 48/50 [00:15<00:00,  3.06trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      " 98%|██████████████████████████████████████████████ | 49/50 [00:15<00:00,  3.08trial/s, best loss: -0.8814102564102565]Fit chain from scratch\n",
      "100%|███████████████████████████████████████████████| 50/50 [00:16<00:00,  3.12trial/s, best loss: -0.8814102564102565]\n",
      "Fit chain from scratch\n",
      "Hyperparameters optimization finished\n",
      "Return tuned chain due to the fact that obtained metric 0.879 equal or bigger than initial (- 5% deviation) 0.831\n",
      "Tuning was finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'depth': 3, 'length': 5, 'nodes': [mlp, bernb, dt, rf, xgboost]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_evo_composed.fine_tune_all_nodes(loss_function=roc_auc,\n",
    "                                       loss_params=None,\n",
    "                                       input_data=input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e702c55",
   "metadata": {},
   "source": [
    "Check the metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "48552727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on training sample: 0.924\n"
     ]
    }
   ],
   "source": [
    "prediction = chain_evo_composed.predict(input_data)\n",
    "print(f'ROC AUC score on training sample: {roc_auc(y_data, prediction.predict):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591b3493",
   "metadata": {},
   "source": [
    "As you can see from the metric value, the model was well trained on the training sample. \n",
    "\n",
    "So, in this notebook, you learned how to run FEDOT for the classification task, both using the API and using more complex constructs from the core based on the functionality of the FEDOT framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
